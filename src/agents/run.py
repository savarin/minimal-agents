from typing import Any
from dataclasses import dataclass

from openai.types.responses import (
    ResponseOutputMessage,
    ResponseOutputRefusal,
    ResponseOutputText,
)

from .agent import Agent, TContext
from .models.interface import (
    Model,
    ModelResponse,
    TResponseInputItem,
    TResponseOutputItem,
)


# from .exceptions import ModelBehaviorError


class AgentsException(Exception):
    """Base class for all exceptions in the Agents SDK."""


class ModelBehaviorError(AgentsException):
    """Exception raised when the model does something unexpected, e.g. calling a tool that doesn't
    exist, or providing malformed JSON.
    """

    message: str

    def __init__(self, message: str):
        self.message = message


# from .items import ItemHelpers, RunItem


class ItemHelpers:
    @classmethod
    def extract_last_content(cls, message: TResponseOutputItem) -> str:
        """Extracts the last text content or refusal from a message."""
        if not isinstance(message, ResponseOutputMessage):
            return ""

        last_content = message.content[-1]

        if isinstance(last_content, ResponseOutputText):
            return last_content.text

        elif isinstance(last_content, ResponseOutputRefusal):
            return last_content.refusal

        else:
            raise ModelBehaviorError(f"Unexpected content type: {type(last_content)}")


# from .result import RunResult


@dataclass
class RunResult:
    input: str | list[TResponseInputItem]
    """The original input items i.e. the items before run() was called. This may be a mutated
    version of the input, if there are handoff input filters that mutate the input.
    """

    new_items: list[TResponseOutputItem]
    """The new items generated during the agent run. These include things like new messages, tool
    calls and their outputs, etc.
    """

    raw_responses: list[ModelResponse]
    """The raw LLM responses generated by the model during the agent run."""

    final_output: Any
    """The output of the last agent."""

    last_agent: Agent[Any]
    """The last agent that was run."""


# src.agents.run


class Runner:
    @classmethod
    async def run(
        cls,
        agent: Agent[TContext],
        input: str | list[TResponseInputItem],
    ) -> RunResult:
        """Run a workflow starting at the given agent. The agent will run in a loop until a final
        output is generated. The loop runs like so:
        1. The agent is invoked with the given input.
        2. If there is a final output (i.e. the agent produces something of type
            `agent.output_type`, the loop terminates.
        3. If there's a handoff, we run the loop again, with the new agent.
        4. Else, we run tool calls (if any), and re-run the loop.

        In two cases, the agent may raise an exception:
        1. If the max_turns is exceeded, a MaxTurnsExceeded exception is raised.
        2. If a guardrail tripwire is triggered, a GuardrailTripwireTriggered exception is raised.

        Note that only the first agent's input guardrails are run.

        Args:
            starting_agent: The starting agent to run.
            input: The initial input to the agent. You can pass a single string for a user message,
                or a list of input items.
            context: The context to run the agent with.
            max_turns: The maximum number of turns to run the agent for. A turn is defined as one
                AI invocation (including any tool calls that might occur).
            hooks: An object that receives callbacks on various lifecycle events.
            run_config: Global settings for the entire agent run.
            previous_response_id: The ID of the previous response, if using OpenAI models via the
                Responses API, this allows you to skip passing in input from the previous turn.

        Returns:
            A run result containing all the inputs, guardrail results and the output of the last
            agent. Agents may perform handoffs, so we don't know the specific type of the output.
        """
        assert isinstance(agent.model, Model)
        assert isinstance(agent.instructions, str)

        response = await agent.model.get_response(
            system_instructions=agent.instructions,
            input=input,
            model_settings=agent.model_settings,
        )

        final_output = ""

        if response.output:
            final_output = ItemHelpers.extract_last_content(response.output[0])

        return RunResult(
            input=input,
            new_items=response.output,
            raw_responses=[response],
            final_output=final_output,
            last_agent=agent,
        )
